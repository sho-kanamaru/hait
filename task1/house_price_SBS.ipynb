{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "data = pd.read_csv('house_price.csv')\n",
    "y = pd.read_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sho/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ここからSBSの実装\n",
    "#特徴量全体から、特定の特徴量を取り除く時に発生しうるパターン全てで機械学習アルゴリズムの予測精度を評価する\n",
    "\n",
    "#①最終的にここまで減らしたいという特徴量の数(k)を決める。\n",
    "#②元々の全体特徴量nから1つ特徴量を削除する時に考えられる組み合わせを全て洗い出す。\n",
    "#③洗い出された全てのパターンにおいてテストデータに対する精度評価を行う。\n",
    "#④③でテストデータに対して最も良い精度を出した特徴量の組み合わせと、精度のスコアを記録しておく(変数に格納する)\n",
    "#⑤全体特徴量nから④の特徴量の組み合わせに含まれていない特徴量を1つ削除する。\n",
    "#⑥n > kとなっていれば②のステップから繰り返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#トレーニングデータの再分割\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xの特徴量の個数を取得\n",
    "dimension = X_train2.shape[1]\n",
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全体特徴量をインデックスとして管理\n",
    "indices = tuple(range(dimension))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全ての特徴量を使って、スコアを計算する\n",
    "lr.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全ての組み合わせで一番スコアが良かったものを格納する配列\n",
    "best_scores = []\n",
    "best_subsets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#特徴量を10個まで削減する\n",
    "k_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73804825174575961, 0.74995545190307711, 0.75674643091719762, 0.7615459807398306, 0.76773268741883016, 0.7709819756401084, 0.77353005012494203, 0.78355679741486661, 0.78792551656051857, 0.7912323754755396, 0.79375982513830667, 0.7959751629299614, 0.79997970261668627, 0.80135312436556805, 0.80257254145503298, 0.80443903342784473, 0.80564987320435777, 0.80928744771722194, 0.81149240683847679, 0.81328074125529359, 0.81480734584636927, 0.81796844415326153, 0.81985554608496647, 0.82123230447571927, 0.82293915956414454, 0.82441245870907987, 0.82527833382214633, 0.82602122724354166, 0.82675279347625841, 0.82733487923337878, 0.82766176981197559, 0.8279092360208562, 0.82816279087048705, 0.83015102689219844, 0.8309152565619522, 0.83129792689471582, 0.83163268269653479, 0.83184855139655589, 0.83204427962373595, 0.83219738797904996, 0.83508634843187624, 0.83683126268458119, 0.8375491188329669, 0.83772137977036243, 0.83785382580524259, 0.83830780739118005, 0.83910805923862386, 0.83976765213700977, 0.84007407021640879, 0.84058201065354587, 0.84087246954825412, 0.84108180428073942, 0.84123819406176603, 0.84139378839973811, 0.8415101776046664, 0.84155265274447633, 0.84155265274456703, 0.84155265274457147, 0.84155265274456093, 0.84155265274457258, 0.84155265274456381, 0.84950811126192194, 0.85195809548925183, 0.85356198974245157, 0.85572381037565926, 0.85830326350386621, 0.85915137538493291, 0.85976658323459532, 0.86030976489358713, 0.86134316005741307, 0.86221110036029969, 0.86269345395185026, 0.8629535517360476, 0.863257000379551, 0.86376964090888952, 0.86399938401352494, 0.86409369347303022, 0.86416634412701865, 0.86420102373559227, 0.86420102373570229, 0.86628284614666784, 0.86661650075776686, 0.86670849750684653, 0.86670849750687573, 0.86823744556472782, 0.86866474138864236, 0.86908993882120333, 0.86914320591519023, 0.86918953946918243, 0.86919985496153451, 0.86920347901702555, 0.86920347901703554, 0.86920347901704442, 0.86974335820313975, 0.86985156541315822, 0.87014723268361727, 0.87085118666695716, 0.87085118666698946, 0.87085118666699823, 0.87142310331905737, 0.87195435885400863, 0.87195435885404626, 0.87379863211345798, 0.87412744698508615, 0.87412744698512601, 0.8744828783793861, 0.87486498094366727, 0.87516308454891623, 0.87516308454894898, 0.87530734524480347, 0.87550898534385024, 0.87563753364428509, 0.87582060602818834, 0.87582060602822875, 0.87582060602823009, 0.87624769393236179, 0.87630354191946669, 0.87630354191950566, 0.8789753004850096, 0.87922516821273633, 0.87996583708473719, 0.88076489449209427, 0.88086384223740755, 0.88105097701348933, 0.8814168003353533, 0.88190417584703118, 0.88238780698105568, 0.88283226209315857, 0.88310207616620073, 0.88311954496970979, 0.88312578256465424, 0.88312578256468244, 0.88353706912571794, 0.883541678704587, 0.88354690732263386, 0.8836109239443708, 0.88413223003965846, 0.88420663012483613, 0.88424236765942577, 0.88424236765944186, 0.88434737402369823, 0.88437802140125166, 0.8846391587775525, 0.88497082541207772, 0.88518094424660598, 0.88535435851797317, 0.8854452395333301, 0.88577336078696189, 0.88597126960328354, 0.88600281632164624, 0.88600281632164923, 0.88600772389040139, 0.88645915249295204, 0.88688730792687842, 0.88706957684452437, 0.88714962458495872, 0.88714962458497493, 0.88714962458499647, 0.88714962458498614, 0.88714962458498969, 0.88714962458498614, 0.88714962458498514, 0.88719429453370191, 0.88723884446548251, 0.88723884446551904, 0.88723884446551315, 0.88723884446551249, 0.88723884446551571, 0.88723884446551138, 0.88723884446552292, 0.88737443694857099, 0.88737443694858453, 0.8873744369485651, 0.8877680323079109, 0.8877680323079119, 0.88875922216067993, 0.88915864253711441, 0.88937015898799343, 0.88943069116777906, 0.88943069116777196, 0.88943069116777274, 0.88940368476775744, 0.88936567150138812, 0.88939330332367994, 0.88939340562059155, 0.88933830062452046, 0.88932639332816676, 0.88932354470029185, 0.88930464989992863, 0.88924262533460596, 0.88917166938385628, 0.88904965042802231, 0.88888606368873713, 0.88875251079807072, 0.88853965747264674, 0.88834359533092455, 0.88814254592284658, 0.887877512270277, 0.88771411881344509, 0.88754420146753232, 0.88731232848268538, 0.8870583617420027, 0.88673359911453997, 0.88629271713123192, 0.88587033029086693, 0.88534351990734683, 0.88487165613693808, 0.88500122842933915, 0.88516583508322122, 0.88517269351333772, 0.8848614038746182, 0.88435469019656754, 0.88383501154463939, 0.88326023969686374, 0.88267291584616714, 0.88212631490812121, 0.88152165826764151, 0.88082673254001453, 0.8800862688260005, 0.8794281629411731, 0.87860970916708736, 0.87768934679101007, 0.877030780986091, 0.8779019239429553, 0.8776436533290618, 0.87785754457011178, 0.87788749605506899, 0.87782676726980213, 0.87750591061356364, 0.87718635508314291, 0.8770268898641721, 0.87657384018749784, 0.87706807636758832, 0.87691994048888156, 0.87632297551794469, 0.87595172952520928, 0.8774717646898883, 0.88367242642889776, 0.88295449879667121, 0.8822749292969374, 0.88190357475558123, 0.88182685326498378, 0.88272900674277233, 0.88228830797518187, 0.88184672771850381, 0.88096417510021197, 0.88038499273095616, 0.87938158204860184, 0.87822496467512334, 0.87665501924596179, 0.87503223013497022, 0.87316637154583088, 0.87154971267049874, 0.87030140786827703, 0.86890728013444729, 0.86683278491909732, 0.86498006979209763, 0.86291770319667283, 0.86068006222604743, 0.85816504658395809, 0.85554246019610891, 0.85134608602629858, 0.84522123234212287, 0.83961262137723913, 0.83239594822198248, 0.82520388214527107, 0.82582100107603429, 0.81663785106004971, 0.81955345974836169, 0.81853279217274411, 0.81520262754400186, 0.81187013637182992, 0.81405302574303717, 0.80944853607873246, 0.80346621659028417, 0.79385609001053647, 0.78259922358373291, 0.76972133205860116, 0.76242406252194228, 0.75523462219454796]\n"
     ]
    }
   ],
   "source": [
    "while dimension > k_features:\n",
    "    scores = []\n",
    "    subsets = []\n",
    "\n",
    "    for c in combinations(indices, r=dimension-1):\n",
    "        lr.fit(X_train2.iloc[:, list(c)], y_train2)\n",
    "        score = lr.score(X_test2.iloc[:, list(c)], y_test2)\n",
    "        # 選択した特徴量のスコアを格納\n",
    "        scores.append(score)\n",
    "        # 選択した特徴量のインデックスを格納\n",
    "        subsets.append(c)\n",
    "        \n",
    "    best = np.argmax(scores)\n",
    "    indices = subsets[best]\n",
    "    best_subsets.append(indices)\n",
    "    best_scores.append(np.max(scores))\n",
    "    dimension -= 1\n",
    "\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トレーニングデータの正答率:  0.887445620493\n",
      "テストデータの正答率:  0.596085324399\n"
     ]
    }
   ],
   "source": [
    "best_scores[np.argmax(best_scores)]\n",
    "index = best_subsets[np.argmax(best_scores)]\n",
    "\n",
    "lr.fit(X_train.iloc[:, list(index)], y_train)\n",
    "print('トレーニングデータの正答率: ', lr.score(X_train.iloc[:, list(index)], y_train))\n",
    "print('テストデータの正答率: ', lr.score(X_test.iloc[:, list(index)], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
